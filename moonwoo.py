# -*- coding: utf-8 -*-
"""moonwoo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qAv83l9yPmdEWpugXn0HUBvib8wSCb-4
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/디지털언어데이터

print("===== 젓가락 논쟁 =====")
print(f"토론 전문-전체 댓글 코사인 유사도: {js_cos:.3f}")
print(f"토론 전문-전체 댓글 의미적 거리(1-유사도): {js_dist:.3f}")
print(f"토론 전문-프레임 댓글(위선/회피 등) 코사인 유사도: {js_frame_cos:.3f}")
print(f"토론 전문-프레임 댓글 의미적 거리(1-유사도): {js_frame_dist:.3f}")

print("\n===== 법인카드 논쟁 =====")
print(f"토론 전문-전체 댓글 코사인 유사도: {card_cos:.3f}")
print(f"토론 전문-전체 댓글 의미적 거리(1-유사도): {card_dist:.3f}")
print(f"토론 전문-프레임 댓글(위선/회피 등) 코사인 유사도: {card_frame_cos:.3f}")
print(f"토론 전문-프레임 댓글 의미적 거리(1-유사도): {card_frame_dist:.3f}")

import pandas as pd

result_df = pd.DataFrame({
    '사안': ["젓가락-전체", "젓가락-프레임", "법인카드-전체", "법인카드-프레임"],
    '코사인 유사도': [js_cos, js_frame_cos, card_cos, card_frame_cos],
    '의미적 거리(1-유사도)': [js_dist, js_frame_dist, card_dist, card_frame_dist]
})
print(result_df.to_markdown(index=False))

import pandas as pd
import re
from konlpy.tag import Okt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# 한글 폰트 설치(Colab 전용)
!apt-get -qq install fonts-nanum > /dev/null
fontpath = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fm.fontManager.addfont(fontpath)
plt.rc('font', family='NanumGothic')
plt.rcParams['axes.unicode_minus'] = False

# Excel 댓글 데이터
df = pd.read_excel("chopsticks.xlsx")
df = df.dropna(subset=['comment', 'num_likes'])
df['num_likes'] = pd.to_numeric(df['num_likes'], errors='coerce').fillna(0)
all_comments = df['comment'].astype(str).tolist()
top100_comments = df.sort_values(by='num_likes', ascending=False)['comment'].astype(str).head(100).tolist()

# 토론 전문 (한 줄, 따옴표)
debate_text_jeosgarag = [
    "이준석 자 그리고 권영국 후보님께 좀 여쭤보겠습니다. 권영국 후보님 그 사실 이재명 후보님이 사실 가족 간의 그런 어떤 좀 특이한 대화나 이런 걸 하셔가지고 문제 되신 건 아까 사과하시고 이렇게 했었는데요. 가장 또 놀라는 것이 혹시 정의당에 아니 그러니까 민주노동당 기준으로 여쭤보고 싶은 게 만약에 어떤 사람이 여성에 대해 가지고 얘기할 때 \"여성의 어떤 성기나 이런 곳에 젓가락을 꽂고 싶다.\" 이런 얘기를 했다 그러면 이거는 여성 혐오에 해당합니까 아닙니까? 권영국그건 뭐 답변하지 않겠습니다.이준석 민주노동당에는 기준이 없습니까? 이런 성폭력적인 발언엔 대해서.권영국 그건 있죠. 그러나 지금 이걸 묻는 취지는 잘 모르겠는데요. 기준은 매우 엄격합니다. 이준석 매우 문제가 되는 발언입니까? 아닙니까? 권영국 우리는 당연히 이제 성적인 학대를 한다든가 이런 부분에 대해서는 누구보다 엄격하게 정하고 있습니다. 이준석 이재명 후보님도 동의하십니까? 이재명 시간을 충분히 주고 질문을 이준석 동의하시는지만 답하시면 됩니다. 동의 안 하시는 겁니까? 이런 발언이 문제 있다는 것은 이재명 시간을 지켜서 하시면 좋죠."
]

# 형태소 분석·불용어 제거 함수
okt = Okt()
stopwords = set(["의", "이", "가", "은", "는", "을", "를", "에", "도", "고", "서", "의", "들", "만", "좀", "진짜", "정말", "것", "듯", "다", "요", "네", "음", "데", "때", "힘", "함", "그리고", "그런", "하다", "입니다"])
def clean_and_tok(txt):
    txt = re.sub(r"[^가-힣a-zA-Z0-9\s]", " ", str(txt))
    words = okt.pos(txt, stem=True)
    return ' '.join([w for w, t in words if t in ['Noun', 'Verb', 'Adjective'] and w not in stopwords and len(w) > 1])

debate_blob = ' '.join([clean_and_tok(x) for x in debate_text_jeosgarag])
all_comments_blob = ' '.join([clean_and_tok(x) for x in all_comments])
top100_blob = ' '.join([clean_and_tok(x) for x in top100_comments])

# TF-IDF·코사인유사도
vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)
X_all = vectorizer.fit_transform([debate_blob, all_comments_blob])
cos_sim_all = cosine_similarity(X_all)[0, 1]
dist_all = 1 - cos_sim_all

X_top100 = vectorizer.fit_transform([debate_blob, top100_blob])
cos_sim_top100 = cosine_similarity(X_top100)[0, 1]
dist_top100 = 1 - cos_sim_top100

# 표 출력
import pandas as pd
result_df = pd.DataFrame({
    "비교쌍": ["전체 댓글-토론 전문", "상위 100개 댓글-토론 전문"],
    "코사인 유사도": [cos_sim_all, cos_sim_top100],
    "의미적 거리(1-유사도)": [dist_all, dist_top100]
})
print(result_df.to_markdown(index=False))

# 그래프
labels = ['전체댓글', '상위100']
distances = [dist_all, dist_top100]
colors = ['#6A5ACD', '#32CD32']
plt.figure(figsize=(6,4))
plt.bar(labels, distances, color=colors)
plt.title("젓가락 논쟁: 토론 전문–댓글 텍스트 의미 거리")
plt.ylabel("Cosine Distance")
plt.ylim(0,1)
plt.tight_layout()
plt.show()

# 공통 단어(진단)
debate_tokens = set(debate_blob.split())
top100_tokens = set(top100_blob.split())
print("토론 전문-상위100 댓글 공통 토큰수:", len(debate_tokens & top100_tokens))
print("공통 토큰 예:", sorted(list(debate_tokens & top100_tokens))[:15])

import pandas as pd
import re
from konlpy.tag import Okt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# 한글 폰트 설치(Colab 전용)
!apt-get -qq install fonts-nanum > /dev/null
fontpath = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fm.fontManager.addfont(fontpath)
plt.rc('font', family='NanumGothic')
plt.rcParams['axes.unicode_minus'] = False

# Excel 댓글 데이터
df = pd.read_excel("beonincard.xlsx")
df = df.dropna(subset=['comment', 'num_likes'])
df['num_likes'] = pd.to_numeric(df['num_likes'], errors='coerce').fillna(0)
all_comments = df['comment'].astype(str).tolist()
top50_comments = df.sort_values(by='num_likes', ascending=False)['comment'].astype(str).head(50).tolist()

# 토론 전문 (한 줄, 따옴표)
debate_text_card = [
    "이준석 예 이재명 후보님, 헌법 8조 잘 아시죠? 이재명 조문은 정확하게 기억 못 하겠네요. 말씀해 보세요. 이준석 예 정당에 관한 부분이니까 모르시죠? 그러니까 정당을 민주적으로 운영해야 된다라는 내용이 헌법 8조의 2항인데요. 제발 그 헌법대로 정당을 운영하셨으면 좋겠다 그런 생각을 했습니다. 사실 민주당의 운영을 보면요. 정당 내부의 민주주의의 실종이라는 말을 들은 지 오래고요. 정당의 당헌 같으면은 국가의 헌법과도 같은 것입니다. 그런데 이 당헌 같은 것을 바꾸고 그러세요 그래서 그 민주당의 당헌을 보면 80조에 보면 여러 가지 범죄 혐의가 있으면 당직이 기소 시에 정지되게 돼 있는데 그것도 이제 마음대로 바꾸시고 이렇게 하는 모습을 보면서 1심 유죄 나오자마자 당헌 80조가 삭제됐거든요. 이렇게 당의 존립 근거가 되는 당헌을 이렇게 마음대로 바꿔버린 위인설법 아니겠습니까? 이재명 후보 전에는 기소된 사람 없었습니까? 그런데 이재명 후보가 기소되고 나니까, 유죄를 선고받으니까 이런 것들을 없앤다는 것 자체가 법체계에 대한 당내의 법 체계에 대한 이해도 별로 없으신 것 같고 그래서 지금도 형사소송법 개정이나 이런 것에 대해 가지고 사회의 규칙이나 제도에 대한 존중 자체가 없는 것이 아니냐라는 비판을 받는 겁니다. 어떻게 보십니까? 앞으로 이런 법률이나 개헌을 진행하는 데 있어서 본인이 관련된 부분은 좀 회피하시고 이렇게 하실 의향이 없으십니까? 이재명 더불어민주당은 역사에 없을 정도로 당원 중심의 민주적 정당으로 바뀌었고 강하고 유능한 정당으로 바꿔서 대한민국 정치사에서 가장 큰 야당의 승리를 이뤄냈고 가장 강력한 수권 정당이 됐습니다. 남의 당 얘기하기보다는 개혁신당은 그 허은아 대표를 그렇게 강제적으로 조치를 하지 않았습니까? 또 김용남 의원도 개혁신당 아닌가요? 그리고 당내 자금 사용 관련해서 부패 혐의로 고발당하고 그랬던 것으로 아는 어쨌든 그런 점도 살펴보시기 바랍니다. 이준석 허은아, 김용남 그렇게 좋으시면 허은아 의원님이 말씀하신 거 제가 이재명 대표에 대해 평가한 거 읽어 드리면요. '매표, 포퓰리즘을 하는 사람이다. 한국판 차베스다.' 김용남 의원은요. '이재명은 대통령은커녕 성남시장의 자격도 없다. 경기도민이 낸 세금으로 횡성 한우보다 더 맛있다는 횡령한우를 사 먹었으면 죗값을 치러야 된다.' 뭐 이런 부분도 반영해 가지고 같이 데려가셨으면 좋겠다 이런 말씀드립니다. 그리고 계속 이제 질문에 질문으로 답하시는 아주 안 좋은 그런 어떤 태도가 있으신데요. 지난번에도 똑같았지만 이제 국민들이 그 수법 잘 알 테니까 자제해 주셨으면 합니다. 오늘 또 이 토론이 있는 날에도 제가 알기로는 이재명 후보님 재판 공판 준비 기일이 있었던 걸로 알고 있습니다. 법인카드 사적 유용 혐의에 대해서 재판 공소장을 보니까 흥미로운 대목이 있습니다. 많은 분들이 '뭐 10만 원 때문에 그러냐?' 그렇게 하는 분들이 있는데 그거는 공직선거법에 대한 부분이고요. 지금 재판 받는 거 보면은 2019년부터 2021년 10월까지 과일만 2791만 원 정도 법인카드로 사셔가지고 사적 유용 때문에 재판받고 계신 거거든요. 259번 과일을 사드셨는데 2791만 원어치를 드셨어요. 과일이 평균 가격을 보니까요. 뭐 종류가 다양하겠죠. 1킬로에 1만 원 정도 하던데요. 이 기준이라면은 2800만 원어치의 과일을 2년 동안 드셨으면은 2.8톤입니다. 혹시 집에 뭐 코끼리 같은 거 키우십니까? 사람이 어떻게 이렇게 많은 과일을 집에서 이렇게 법인카드로 결제할 수 있는지 혼자 드신 겁니까? 아니면 어떻게 하신 겁니까? 궁금합니다. 이재명 네 그래서 엉터리라는 거예요. 그거는 제가 쓴 일도 없고, 그거 쓰는 거 본 일도 없고 실무 부서에서 과일 거래를 했다는데 그걸 제가 어떻게 압니까? 그걸 전부 제가 '횡령을 했다.', '지시를 했다.', '알고 그랬다.'라고 기소를 했는데 그게 바로 엉터리 기소라는 뜻이고요. 그 사건에서는 제가 그걸 '지시한 것으로 보여진다'라고 기소를 했는데 그런 근거 자료가 한 개도 없어요. 그래서 엉터리 조작 기소다 이렇게 얘기하는 겁니다."
]

# 형태소 분석·불용어 제거 함수
okt = Okt()
stopwords = set(["의", "이", "가", "은", "는", "을", "를", "에", "도", "고", "서", "의", "들", "만", "좀", "진짜", "정말", "것", "듯", "다", "요", "네", "음", "데", "때", "힘", "함", "그리고", "그런", "하다", "입니다"])
def clean_and_tok(txt):
    txt = re.sub(r"[^가-힣a-zA-Z0-9\s]", " ", str(txt))
    words = okt.pos(txt, stem=True)
    return ' '.join([w for w, t in words if t in ['Noun', 'Verb', 'Adjective'] and w not in stopwords and len(w) > 1])

debate_blob = ' '.join([clean_and_tok(x) for x in debate_text_card])
all_comments_blob = ' '.join([clean_and_tok(x) for x in all_comments])
top50_blob = ' '.join([clean_and_tok(x) for x in top50_comments])

# TF-IDF·코사인유사도
vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=1)
X_all = vectorizer.fit_transform([debate_blob, all_comments_blob])
cos_sim_all = cosine_similarity(X_all)[0, 1]
dist_all = 1 - cos_sim_all

X_top50 = vectorizer.fit_transform([debate_blob, top50_blob])
cos_sim_top50 = cosine_similarity(X_top50)[0, 1]
dist_top50 = 1 - cos_sim_top50

# 표 출력
import pandas as pd
result_df = pd.DataFrame({
    "비교쌍": ["전체 댓글-토론 전문", "상위 50개 댓글-토론 전문"],
    "코사인 유사도": [cos_sim_all, cos_sim_top50],
    "의미적 거리(1-유사도)": [dist_all, dist_top50]
})
print(result_df.to_markdown(index=False))

# 그래프
labels = ['전체댓글', '상위50']
distances = [dist_all, dist_top50]
colors = ['#6A5ACD', '#32CD32']
plt.figure(figsize=(6,4))
plt.bar(labels, distances, color=colors)
plt.title("법인카드 논쟁: 토론 전문–댓글 텍스트 의미 거리")
plt.ylabel("Cosine Distance")
plt.ylim(0,1)
plt.tight_layout()
plt.show()

# 공통 단어(진단)
debate_tokens = set(debate_blob.split())
top50_tokens = set(top50_blob.split())
print("토론 전문-상위50 댓글 공통 토큰수:", len(debate_tokens & top50_tokens))
print("공통 토큰 예:", sorted(list(debate_tokens & top50_tokens))[:15])

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# 한글 폰트(Colab 기준)
fontpath = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'
fm.fontManager.addfont(fontpath)
plt.rc('font', family='NanumGothic')
plt.rcParams['axes.unicode_minus'] = False

labels = ['젓가락-전체', '젓가락-top50', '법인카드-전체', '법인카드-top50']
distances = [0.610, 0.784, 0.644, 0.838]
colors = ['#6A5ACD', '#32CD32', '#6495ED', '#FFD580']

plt.figure(figsize=(9,5))
plt.bar(labels, distances, color=colors)
plt.title("사안별 토론 전문–댓글 텍스트 의미 거리(인지부조화 지표)")
plt.ylabel("Cosine Distance")
plt.ylim(0,1)
for i, v in enumerate(distances):
    plt.text(i, v+0.04, f"{v:.2f}", ha='center', fontsize=12)
plt.tight_layout()
plt.show()